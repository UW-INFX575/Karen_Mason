{
 "metadata": {
  "name": "",
  "signature": "sha256:fe95a97c103bfb3d2c7db6ac591ad73864acd77f5e1b91f867a26e4e3580a7c2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import the models needed.\n",
      "import nltk\n",
      "import os\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from nltk.collocations import *\n",
      "import csv\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 330
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print os.getcwd()\n",
      "# set the working directory on Karen's computer\n",
      "#os.chdir('\\Users\\Karen\\Documents')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\Karen\\Documents\\575\\Assignment2\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stem_function(filename):\n",
      "    \"\"\"Function to stem the words in the given files using the Snowball Stemmer \n",
      "    \"\"\"\n",
      "    \n",
      "    stemmer = SnowballStemmer(\"english\",ignore_stopwords = False)\n",
      "    stemmed_words = []\n",
      "\n",
      "    for word in filename:\n",
      "        a = stemmer.stem(word)\n",
      "        stemmed_words.append(a)\n",
      "    return stemmed_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 331
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stop_word(filename):\n",
      "    \"\"\"Remove stop words from the files based on the NLTK stop word list. \n",
      "    \"\"\"\n",
      "    stop = stopwords.words('english')\n",
      "    lstfile_stem_stop = []\n",
      "\n",
      "    for i in filename:\n",
      "        if i not in stop:\n",
      "            a = i\n",
      "            lstfile_stem_stop.append(a)\n",
      "\n",
      "    return lstfile_stem_stop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_unigrams(filename):\n",
      "    \"\"\" Create unigram of all words used in the file(s)\n",
      "    \"\"\"\n",
      "    #Create unigrams\n",
      "    bgs = nltk.ngrams(filename,1)\n",
      "\n",
      "    #compute frequency distribution for all the unigrams in the text\n",
      "    fdist_1 = {}\n",
      "    fdist_1 = nltk.FreqDist(bgs)\n",
      "    for k,v in fdist_1.items():\n",
      "        fdist_0[k] = v\n",
      "\n",
      "    return fdist_1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_bigrams(filename):\n",
      "    \"\"\" Create bigram of all words used in the file(s)\n",
      "    \"\"\"\n",
      "    #Create bigrams\n",
      "    bgs = nltk.bigrams(filename)\n",
      "\n",
      "    #compute frequency distribution for all the bigrams in the text\n",
      "    fdist_2 = {}\n",
      "    fdist_2 = nltk.FreqDist(bgs)\n",
      "    for k,v in fdist_2.items():\n",
      "        fdist_0[k] = v\n",
      "    \n",
      "    return fdist_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 336
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_trigrams(filename):\n",
      "    \"\"\" Create bigram of all words used in the file(s)\n",
      "    \"\"\"\n",
      "    #Create trigrams\n",
      "    bgs = nltk.trigrams(filename)\n",
      "\n",
      "    #compute frequency distribution for all the unigrams in the text\n",
      "    fdist_3 = {}\n",
      "    fdist_3 = nltk.FreqDist(bgs)\n",
      "    for k,v in fdist_3.items():\n",
      "        fdist_0[k] = v\n",
      "\n",
      "    return fdist_3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 337
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename_root = str(633422)\n",
      "files = 'files'\n",
      "all_files = [] #list of all txt files to be processed\n",
      "work_file = [] #working filename for use in this code\n",
      "work_variable = []  #variable for manipulating file for stemming and stopping\n",
      "uni_file = []\n",
      "bi_file = []\n",
      "tri_file = []\n",
      "\n",
      "for x in range (0,10): \n",
      "    filename = filename_root+str(x)+'.txt'\n",
      "    work_file_name = files+str(x)+'.csv'\n",
      "    uni_file_name = 'uni'+filename_root+str(x)+'.csv'\n",
      "    bi_file_name = 'bi'+filename_root+str(x)+'.csv'\n",
      "    tri_file_name = 'tri'+filename_root+str(x)+'.csv'\n",
      "    working = files+str(x)\n",
      "    uni_sum_name = 'uni_sum.csv'\n",
      "    bi_sum_name = 'bi_sum.csv'\n",
      "    tri_sum_name = 'tri_sum.csv'\n",
      "    \n",
      "    #create master list of files names\n",
      "    work_variable.append(working)\n",
      "    all_files.append(filename)\n",
      "    work_file.append(work_file_name)\n",
      "    uni_file.append(uni_file_name)\n",
      "    bi_file.append(bi_file_name)\n",
      "    tri_file.append(tri_file_name)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 338
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_unigram_file(filename, outfilename):\n",
      "    \"\"\" Write the contents of the variable to  file\n",
      "    \"\"\"\n",
      "    \n",
      "    with open(outfilename, 'ab') as csvfile:\n",
      "        filename = csv.writer(csvfile, delimiter=',',quotechar=\" \", quoting=csv.QUOTE_MINIMAL)\n",
      "        filename.writerow([str(k),v])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 339
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_bigram_file(filename, outfilename):\n",
      "    \"\"\" Write the contents of the variable to  file\n",
      "    \"\"\"\n",
      "   \n",
      "    with open(outfilename, 'ab') as csvfile:\n",
      "        filename = csv.writer(csvfile, delimiter=',',quotechar=\" \", quoting=csv.QUOTE_MINIMAL)\n",
      "        filename.writerow([str(k),v])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_trigram_file(filename, outfilename):\n",
      "    \"\"\"Calculate the bigram and Write the contents of the variable to  file\n",
      "       \"\"\"\n",
      "    with open(outfilename, 'ab') as csvfile:\n",
      "        filename = csv.writer(csvfile, delimiter=',',quotechar=\" \", quoting=csv.QUOTE_MINIMAL)\n",
      "        filename.writerow([str(k),v])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 341
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = 'files'\n",
      "counter = 0\n",
      "\n",
      "for x in all_files:\n",
      "    \n",
      "    uni_file_name = uni_file[counter]\n",
      "    bi_file_name = bi_file[counter]\n",
      "    tri_file_name = tri_file[counter]\n",
      "    work_variable = work_variable[counter]\n",
      "    \n",
      "    \n",
      "    work_variable = open(all_files[counter],'r')    \n",
      "    work_variable = work_variable.read()   \n",
      "    work_variable = work_variable.split()\n",
      "    \n",
      "    \n",
      "    work_variable_stem =  stem_function(work_variable)\n",
      "    work_variable_stem_stop = stop_word(work_variable_stem)\n",
      "   \n",
      "    \n",
      "    unigram_list = create_unigrams(work_variable_stem_stop)   \n",
      "    create_unigram_file(unigram_list, uni_file_name)\n",
      "    \n",
      "    bigram_list = create_bigrams(work_variable_stem_stop)   \n",
      "    #print bigram_list\n",
      "    create_bigram_file(bigram_list, bi_file_name)\n",
      "    \n",
      "    trigram_list = create_trigrams(work_variable_stem_stop)   \n",
      "    create_trigram_file(trigram_list, tri_file_name)    \n",
      "    counter += 1\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 342
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#def stem_function(filename)   DELETE ONCE FUNCTIONS ABOVE ARE WORKING\n",
      "#Stem the words in the file\n",
      "#from nltk.stem.snowball import SnowballStemmer\n",
      "stemmer = SnowballStemmer(\"english\",ignore_stopwords = False)\n",
      "stemmed_words = []\n",
      "\n",
      "for word in file0:\n",
      "    #print(stemmer.stem(word))\n",
      "    a = stemmer.stem(word)\n",
      "    stemmed_words.append(a)\n",
      "    \n",
      "print stemmed_words[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['~~', '1.', 'a', u'dispos', u'garment', u'protector', u'comprising:', 'a)', 'a', u'protector']\n"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#process stop words   DELETE ONCE FUNCTIONS ABOVE ARE WORKING\n",
      "\n",
      "stop = stopwords.words('english')\n",
      "lstfile_stem_stop = []\n",
      "\n",
      "for i in stemmed_words:\n",
      "    if i not in stop:\n",
      "        a = i\n",
      "        lstfile_stem_stop.append(a)\n",
      "\n",
      "#tplfile_stem_stop = tuple(lstfile_stem_stop)\n",
      "\n",
      "print lstfile_stem_stop[:10]\n",
      "#print tplfile_stem_stop[:10]\n",
      "#print type(tplfile_stem_stop)\n",
      "#http://stackoverflow.com/questions/19130512/stopword-removal-with-nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['~~', '1.', u'dispos', u'garment', u'protector', u'comprising:', 'a)', u'protector', u'cover', u'front']\n"
       ]
      }
     ],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"     DELETE WHEN ABOVE ARE WORKING\n",
      "#Create unigrams   \n",
      "bgs = nltk.ngrams(lstfile_stem_stop,1)\n",
      "\n",
      "\n",
      "#compute frequency distribution for all the unigrams in the text and write to a file\n",
      "fdist_0 = {}\n",
      "fdist = nltk.FreqDist(bgs)\n",
      "for k,v in fdist.items():\n",
      "    fdist_0[k] = v\n",
      "    with open('eggs.csv', 'ab') as csvfile:\n",
      "        spamwriter = csv.writer(csvfile, delimiter=',',quotechar=\"'\", quoting=csv.QUOTE_MINIMAL)\n",
      "        spamwriter.writerow([str(k),v])\n",
      "    print str(k),v\n",
      "#filename to save to\n",
      "#outfile = 'testklm'\n",
      "\n",
      "#print fdist_0\n",
      "#create_unigram_file(fdist_0, outfile)\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'downward',) 4\n",
        "(u'and,',) 4\n",
        "('2.',) 1\n",
        "(u'strip',) 2\n",
        "(u'surfac',) 8\n",
        "('a)',) 4\n",
        "(u'chang',) 2\n",
        "(u'garment',) 7\n",
        "(u'end',) 54\n",
        "(u'neck',) 7\n",
        "(u'section',) 20\n",
        "(u'move',) 4\n",
        "(u'tearabl',) 6\n",
        "(u'portion',) 8\n",
        "(u'back',) 10\n",
        "(u'comprising:',) 4\n",
        "(u'user;',) 6\n",
        "(u'section;',) 1\n",
        "(u'strap',) 31\n",
        "(u'adapt',) 3\n",
        "(u'adhes',) 6\n",
        "(u'compris',) 4\n",
        "(u'dispos',) 4\n",
        "('c)',) 4\n",
        "(u'tear',) 8\n",
        "(u'stomach',) 4\n",
        "(u'remov',) 2\n",
        "(u'perfor',) 6\n",
        "(u'torn',) 2\n",
        "(u'extend',) 2\n",
        "(u'cover,',) 4\n",
        "(u'cover',) 16\n",
        "(u'second',) 36\n",
        "(u'two',) 2\n",
        "(u'cover.',) 4\n",
        "(u'produc',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "(u'form',) 6\n",
        "(u'wherein',) 8\n",
        "(u'one',) 9\n",
        "(u'user',) 6\n",
        "(u'protector',) 40\n",
        "(u'along',) 4\n",
        "(u'open',) 8\n",
        "(u'side',) 12\n",
        "(u'joinabl',) 4\n",
        "(u'strap;',) 1\n",
        "(u'includ',) 6\n",
        "(u'join',) 8\n",
        "(u'surface,',) 4\n",
        "('4.',) 1\n",
        "(u'liquid',) 4\n",
        "(u'collect',) 4\n",
        "(u'bottom',) 4\n",
        "(u'chest',) 4\n",
        "(u'front',) 16\n",
        "(u'close',) 4\n",
        "('1.',) 1\n",
        "('3.',) 1\n",
        "(u'quick',) 1\n",
        "(u'use',) 1\n",
        "(u'pouch',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "(u'permit',) 2\n",
        "(u'side,',) 4\n",
        "(u'end,',) 4\n",
        "(u'storag',) 4\n",
        "(u'top',) 8\n",
        "(u'support',) 18\n",
        "(u'around',) 2\n",
        "(u'length',) 2\n",
        "('~~',) 1\n",
        "(u'fold',) 4\n",
        "(u'first',) 46\n",
        "(u'torn,',) 2\n",
        "(u'posit',) 24\n",
        "('b)',) 4\n",
        "(u'least',) 5\n",
        "(u'particul',) 4\n",
        "(u'sections,',) 2\n"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create bigrams   DELETE WHEN ABOVE ARE WORKING\n",
      "bgs = nltk.bigrams(lstfile_stem_stop)\n",
      "\n",
      "#compute frequency distribution for all the bigrams in the text\n",
      "fdist_0 = {}\n",
      "fdist = nltk.FreqDist(bgs)\n",
      "for k,v in fdist.items():\n",
      "    fdist_0[k] = v\n",
      "\n",
      "print fdist_0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{(u'produc', u'second'): 2, (u'first', u'second'): 4, (u'along', u'front'): 4, ('~~', '1.'): 1, (u'strap', u'first'): 2, (u'user;', 'c)'): 2, ('a)', u'protector'): 4, (u'cover,', u'pouch'): 4, (u'posit', u'storag'): 4, (u'compris', u'strap'): 2, (u'first', u'strap'): 8, (u'posit', u'strap'): 2, ('4.', u'dispos'): 1, (u'cover', u'second'): 4, (u'strap', u'tear'): 4, (u'end,', u'front'): 4, (u'surface,', u'first'): 4, (u'pouch', u'posit'): 4, (u'user;', u'and,'): 4, (u'end', u'bottom'): 4, (u'user', u'wherein'): 4, (u'second', u'side,'): 4, (u'cover.', '4.'): 1, (u'extend', u'first'): 2, (u'section', u'second'): 2, (u'end', u'strip'): 2, (u'front', u'back'): 4, (u'back', u'surface,'): 4, (u'wherein', u'strap'): 4, (u'side', u'protector'): 2, (u'strip', u'join'): 2, (u'perfor', u'torn,'): 2, (u'length', u'strap'): 1, (u'join', u'second'): 4, ('3.', u'dispos'): 1, (u'two', u'strap'): 2, (u'protector', u'cover.'): 4, (u'end', u'chang'): 2, (u'portion', u'chest'): 4, (u'joinabl', u'form'): 2, (u'open', u'posit'): 8, (u'includ', u'least'): 4, (u'storag', u'second'): 4, (u'first', u'side'): 8, (u'end', u'portion'): 4, (u'section', u'tearabl'): 1, (u'neck', u'user;'): 1, (u'back', u'form'): 4, (u'support', u'posit'): 4, (u'support', u'adapt'): 3, (u'perfor', u'adhes'): 1, (u'end', u'first'): 2, (u'strap', u'wherein'): 2, (u'chang', u'length'): 2, (u'cover', u'wherein'): 2, (u'strap', u'sections,'): 2, (u'liquid', u'move'): 4, (u'end', u'second'): 4, (u'dispos', u'garment'): 4, (u'one', u'first'): 4, (u'strap', u'section'): 14, (u'cover', u'around'): 2, (u'protector', u'support'): 11, (u'end', u'posit'): 2, (u'end', u'includ'): 2, (u'protector', u'comprising:'): 4, (u'bottom', u'end,'): 4, (u'posit', u'top'): 4, (u'tear', u'end'): 8, (u'section', u'joinabl'): 2, (u'top', u'end'): 8, (u'first', u'end'): 22, (u'joinabl', u'adhes'): 2, (u'around', u'back'): 2, ('b)', u'protector'): 3, (u'chest', u'stomach'): 4, (u'perfor', u'least'): 1, (u'form', u'fold'): 4, (u'cover', u'front'): 8, (u'permit', u'quick'): 1, (u'includ', u'adhes'): 2, (u'wherein', u'protector'): 4, (u'pouch', u'top'): 4, (u'stomach', u'user;'): 4, (u'neck', u'user'): 6, (u'support', u'compris'): 4, (u'quick', u'remov'): 1, (u'support', u'first'): 4, (u'section', u'first'): 8, (u'sections,', u'first'): 2, (u'second', u'strap'): 8, (u'end', u'strap'): 2, (u'end', u'protector'): 14, (u'section', u'posit'): 2, (u'second', u'side'): 4, (u'first', u'close'): 4, (u'torn,', u'first'): 2, (u'collect', u'particul'): 4, (u'front', u'portion'): 4, (u'end', u'join'): 4, (u'protector', u'cover'): 12, (u'protector', u'cover,'): 4, (u'remov', u'protector'): 2, (u'adhes', u'section'): 6, (u'section;', 'c)'): 1, (u'surfac', u'protector'): 4, (u'one', u'tearabl'): 4, (u'permit', u'remov'): 1, (u'posit', u'collect'): 4, ('b)', u'neck'): 1, (u'surfac', u'back'): 4, (u'tearabl', u'perfor'): 6, (u'support', u'garment'): 3, (u'end', u'produc'): 2, (u'end', u'open'): 4, (u'downward', u'along'): 4, (u'posit', u'extend'): 2, (u'second', u'end'): 16, (u'least', u'one'): 5, (u'protector', u'neck'): 4, (u'form', u'strap'): 2, (u'side', u'first'): 6, (u'side', u'second'): 4, (u'posit', u'second'): 4, (u'comprising:', 'a)'): 4, (u'section', u'includ'): 1, (u'garment', u'protector'): 7, (u'protector', u'use'): 1, (u'user', u'second'): 2, (u'fold', u'one'): 4, (u'perfor', u'torn'): 2, (u'particul', u'liquid'): 4, (u'strap', u'section;'): 1, (u'and,', 'b)'): 4, ('2.', u'dispos'): 1, (u'move', u'downward'): 4, (u'posit', u'cover'): 4, (u'front', u'surfac'): 8, ('1.', u'dispos'): 1, (u'compris', u'two'): 2, (u'strap', u'includ'): 3, (u'strap;', 'c)'): 1, (u'back', u'neck'): 2, (u'torn', u'permit'): 2, (u'use', u'user;'): 1, (u'strap', u'join'): 2, (u'second', u'open'): 4, (u'adapt', u'support'): 3, (u'portion', u'second'): 2, (u'end', u'support'): 4, (u'join', u'first'): 4, (u'cover.', '3.'): 1, (u'strap', u'tearabl'): 1, (u'section', u'tear'): 4, (u'length', u'strap;'): 1, ('c)', u'pouch'): 4, (u'side,', u'first'): 4, (u'cover.', '2.'): 1, (u'end', u'joinabl'): 2, (u'one', u'adhes'): 1, (u'close', u'posit'): 4, (u'portion', u'first'): 2}\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create trigrams  DELETE WHEN ABOVE FUNCTION IS WORKING PROPERLY\n",
      "\n",
      "#Create your bigrams\n",
      "bgs = nltk.trigrams(lstfile_stem_stop)\n",
      "\n",
      "#compute frequency distribution for all the trigrams in the text\n",
      "fdist_0_tri = {}\n",
      "fdist = nltk.FreqDist(bgs)\n",
      "for k,v in fdist.items():\n",
      "    fdist_0_tri[k] = v\n",
      "    print k,v\n",
      "#print fdist_0_tri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('b)', u'protector', u'support') 3\n",
        "(u'one', u'first', u'close') 4\n",
        "(u'protector', u'cover', u'front') 4\n",
        "('c)', u'pouch', u'posit') 4\n",
        "(u'collect', u'particul', u'liquid') 4\n",
        "(u'portion', u'chest', u'stomach') 4\n",
        "(u'strap', u'section', u'joinabl') 2\n",
        "(u'perfor', u'adhes', u'section') 1\n",
        "(u'strap', u'first', u'end') 2\n",
        "(u'end', u'support', u'first') 4\n",
        "(u'adhes', u'section', u'posit') 2\n",
        "(u'length', u'strap;', 'c)') 1\n",
        "(u'sections,', u'first', u'strap') 2\n",
        "(u'first', u'strap', u'tear') 2\n",
        "(u'two', u'strap', u'sections,') 2\n",
        "(u'posit', u'strap', u'section') 1\n",
        "(u'section', u'first', u'strap') 2\n",
        "(u'section;', 'c)', u'pouch') 1\n",
        "(u'around', u'back', u'neck') 2\n",
        "(u'end', u'second', u'end') 2\n",
        "(u'end', u'protector', u'cover') 6\n",
        "(u'second', u'side', u'protector') 2\n",
        "(u'protector', u'use', u'user;') 1\n",
        "(u'and,', 'b)', u'protector') 3\n",
        "(u'cover,', u'pouch', u'top') 4\n",
        "(u'front', u'portion', u'chest') 4\n",
        "(u'section', u'joinabl', u'form') 2\n",
        "(u'neck', u'user', u'wherein') 4\n",
        "(u'adhes', u'section', u'second') 2\n",
        "(u'cover', u'front', u'surfac') 4\n",
        "(u'join', u'second', u'side') 4\n",
        "(u'cover.', '3.', u'dispos') 1\n",
        "('a)', u'protector', u'cover') 4\n",
        "(u'and,', 'b)', u'neck') 1\n",
        "(u'section', u'posit', u'strap') 2\n",
        "(u'section', u'tear', u'end') 4\n",
        "(u'user;', u'and,', 'b)') 4\n",
        "(u'torn', u'permit', u'remov') 1\n",
        "(u'permit', u'quick', u'remov') 1\n",
        "(u'front', u'surfac', u'back') 4\n",
        "(u'section', u'tearabl', u'perfor') 1\n",
        "(u'end', u'produc', u'second') 2\n",
        "(u'second', u'side,', u'first') 4\n",
        "(u'form', u'fold', u'one') 4\n",
        "(u'tear', u'end', u'chang') 2\n",
        "(u'least', u'one', u'tearabl') 4\n",
        "(u'remov', u'protector', u'use') 1\n",
        "(u'chang', u'length', u'strap') 1\n",
        "(u'support', u'posit', u'cover') 4\n",
        "(u'move', u'downward', u'along') 4\n",
        "(u'first', u'close', u'posit') 4\n",
        "(u'posit', u'collect', u'particul') 4\n",
        "(u'second', u'end', u'protector') 4\n",
        "(u'user', u'second', u'end') 2\n",
        "(u'section', u'second', u'strap') 2\n",
        "(u'along', u'front', u'surfac') 4\n",
        "(u'support', u'adapt', u'support') 3\n",
        "(u'strap', u'section', u'includ') 1\n",
        "(u'strap', u'tearabl', u'perfor') 1\n",
        "(u'remov', u'protector', u'neck') 1\n",
        "(u'comprising:', 'a)', u'protector') 4\n",
        "(u'joinabl', u'form', u'strap') 2\n",
        "(u'one', u'adhes', u'section') 1\n",
        "(u'cover.', '4.', u'dispos') 1\n",
        "('3.', u'dispos', u'garment') 1\n",
        "(u'liquid', u'move', u'downward') 4\n",
        "(u'tearabl', u'perfor', u'torn,') 2\n",
        "(u'permit', u'remov', u'protector') 1\n",
        "(u'second', u'end', u'second') 2\n",
        "(u'support', u'compris', u'strap') 2\n",
        "(u'first', u'end', u'join') 4\n",
        "(u'section', u'first', u'end') 6\n",
        "(u'downward', u'along', u'front') 4\n",
        "(u'second', u'strap', u'section') 6\n",
        "(u'first', u'end', u'strap') 2\n",
        "(u'protector', u'cover', u'second') 4\n",
        "(u'first', u'end', u'portion') 2\n",
        "(u'use', u'user;', 'c)') 1\n",
        "(u'end', u'protector', u'cover,') 4\n",
        "(u'torn,', u'first', u'strap') 2\n",
        "(u'wherein', u'strap', u'includ') 3\n",
        "(u'end', u'bottom', u'end,') 4\n",
        "(u'cover.', '2.', u'dispos') 1\n",
        "(u'end', u'join', u'first') 2\n",
        "(u'second', u'end', u'portion') 2\n",
        "(u'posit', u'strap', u'tearabl') 1\n",
        "(u'chang', u'length', u'strap;') 1\n",
        "(u'adhes', u'section', u'first') 2\n",
        "(u'posit', u'second', u'end') 4\n",
        "(u'includ', u'adhes', u'section') 2\n",
        "(u'protector', u'cover.', '2.') 1\n",
        "(u'strap', u'tear', u'end') 4\n",
        "(u'form', u'strap', u'wherein') 2\n",
        "(u'tear', u'end', u'joinabl') 2\n",
        "(u'quick', u'remov', u'protector') 1\n",
        "(u'first', u'end', u'first') 2\n",
        "(u'support', u'garment', u'protector') 3\n",
        "(u'user', u'wherein', u'protector') 4\n",
        "(u'compris', u'two', u'strap') 2\n",
        "(u'front', u'back', u'form') 4\n",
        "(u'wherein', u'strap', u'section') 1\n",
        "(u'end', u'portion', u'first') 2\n",
        "(u'chest', u'stomach', u'user;') 4\n",
        "(u'perfor', u'least', u'one') 1\n",
        "(u'length', u'strap', u'section;') 1\n",
        "(u'includ', u'least', u'one') 4\n",
        "(u'cover', u'around', u'back') 2\n",
        "(u'fold', u'one', u'first') 4\n",
        "(u'posit', u'extend', u'first') 2\n",
        "(u'back', u'surface,', u'first') 4\n",
        "(u'open', u'posit', u'top') 4\n",
        "(u'second', u'end', u'posit') 2\n",
        "(u'strap', u'section', u'tear') 4\n",
        "(u'produc', u'second', u'strap') 2\n",
        "(u'back', u'neck', u'user') 2\n",
        "(u'storag', u'second', u'open') 4\n",
        "(u'cover', u'front', u'portion') 4\n",
        "(u'end', u'open', u'posit') 4\n",
        "(u'end', u'protector', u'support') 4\n",
        "(u'join', u'first', u'side') 4\n",
        "(u'strap;', 'c)', u'pouch') 1\n",
        "(u'end', u'second', u'strap') 2\n",
        "(u'pouch', u'posit', u'second') 4\n",
        "(u'tear', u'end', u'includ') 2\n",
        "(u'extend', u'first', u'end') 2\n",
        "(u'garment', u'protector', u'neck') 3\n",
        "(u'protector', u'support', u'posit') 4\n",
        "(u'end', u'portion', u'second') 2\n",
        "(u'end', u'strap', u'join') 2\n",
        "(u'support', u'first', u'end') 4\n",
        "(u'side', u'protector', u'cover') 2\n",
        "(u'posit', u'top', u'end') 4\n",
        "(u'portion', u'second', u'strap') 2\n",
        "(u'joinabl', u'adhes', u'section') 2\n",
        "(u'back', u'form', u'fold') 4\n",
        "(u'second', u'end', u'strip') 2\n",
        "(u'second', u'end', u'support') 4\n",
        "(u'portion', u'first', u'strap') 2\n",
        "(u'protector', u'cover', u'wherein') 2\n",
        "(u'strap', u'section', u'tearabl') 1\n",
        "('4.', u'dispos', u'garment') 1\n",
        "(u'surfac', u'protector', u'cover.') 4\n",
        "(u'strap', u'sections,', u'first') 2\n",
        "(u'posit', u'storag', u'second') 4\n",
        "(u'end', u'first', u'end') 2\n",
        "(u'adapt', u'support', u'garment') 3\n",
        "(u'protector', u'neck', u'user;') 1\n",
        "('~~', '1.', u'dispos') 1\n",
        "(u'side', u'first', u'end') 6\n",
        "(u'first', u'end', u'second') 2\n",
        "(u'pouch', u'top', u'end') 4\n",
        "(u'front', u'surfac', u'protector') 4\n",
        "(u'tearabl', u'perfor', u'adhes') 1\n",
        "(u'compris', u'strap', u'first') 2\n",
        "(u'protector', u'cover.', '4.') 1\n",
        "(u'tearabl', u'perfor', u'torn') 2\n",
        "(u'perfor', u'torn', u'permit') 2\n",
        "(u'posit', u'cover', u'front') 4\n",
        "(u'one', u'tearabl', u'perfor') 4\n",
        "(u'end', u'strip', u'join') 2\n",
        "(u'end', u'join', u'second') 2\n",
        "(u'open', u'posit', u'collect') 4\n",
        "('2.', u'dispos', u'garment') 1\n",
        "('1.', u'dispos', u'garment') 1\n",
        "(u'strip', u'join', u'second') 2\n",
        "(u'top', u'end', u'bottom') 4\n",
        "(u'protector', u'comprising:', 'a)') 4\n",
        "(u'end', u'joinabl', u'adhes') 2\n",
        "(u'cover', u'second', u'end') 4\n",
        "(u'protector', u'support', u'adapt') 3\n",
        "(u'tear', u'end', u'produc') 2\n",
        "(u'tearabl', u'perfor', u'least') 1\n",
        "(u'neck', u'user', u'second') 2\n",
        "(u'close', u'posit', u'storag') 4\n",
        "(u'surfac', u'back', u'surface,') 4\n",
        "(u'surface,', u'first', u'side') 4\n",
        "(u'protector', u'cover,', u'pouch') 4\n",
        "(u'section', u'includ', u'least') 1\n",
        "(u'strap', u'join', u'first') 2\n",
        "(u'strap', u'section;', 'c)') 1\n",
        "(u'user;', 'c)', u'pouch') 2\n",
        "(u'end', u'chang', u'length') 2\n",
        "(u'cover', u'wherein', u'strap') 2\n",
        "(u'protector', u'support', u'compris') 4\n",
        "(u'first', u'end', u'protector') 10\n",
        "(u'side,', u'first', u'second') 4\n",
        "(u'side', u'second', u'side,') 4\n",
        "(u'torn', u'permit', u'quick') 1\n",
        "(u'protector', u'cover.', '3.') 1\n",
        "(u'protector', u'cover', u'around') 2\n",
        "(u'strap', u'section', u'first') 6\n",
        "(u'end', u'posit', u'extend') 2\n",
        "(u'neck', u'user;', 'c)') 1\n",
        "(u'support', u'compris', u'two') 2\n",
        "(u'end', u'includ', u'adhes') 2\n",
        "('b)', u'neck', u'user') 1\n",
        "(u'second', u'strap', u'tear') 2\n",
        "(u'least', u'one', u'adhes') 1\n",
        "(u'second', u'side', u'first') 2\n",
        "(u'stomach', u'user;', u'and,') 4\n",
        "(u'second', u'open', u'posit') 4\n",
        "(u'top', u'end', u'open') 4\n",
        "(u'first', u'second', u'end') 4\n",
        "(u'wherein', u'protector', u'support') 4\n",
        "(u'first', u'strap', u'section') 6\n",
        "(u'strap', u'includ', u'least') 3\n",
        "(u'first', u'side', u'first') 4\n",
        "(u'strap', u'wherein', u'strap') 2\n",
        "(u'bottom', u'end,', u'front') 4\n",
        "(u'protector', u'neck', u'user') 3\n",
        "(u'first', u'side', u'second') 4\n",
        "(u'garment', u'protector', u'comprising:') 4\n",
        "(u'dispos', u'garment', u'protector') 4\n",
        "(u'particul', u'liquid', u'move') 4\n",
        "(u'perfor', u'torn,', u'first') 2\n",
        "(u'end,', u'front', u'back') 4\n"
       ]
      }
     ],
     "prompt_number": 210
    }
   ],
   "metadata": {}
  }
 ]
}